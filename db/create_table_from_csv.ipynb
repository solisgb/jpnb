{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9b9583-a1fe-49c5-beca-16d8a3029144",
   "metadata": {},
   "source": [
    "# Saves an sql file with create table commands for data stored in one or more csv files (basic)\n",
    "Reads a series of csv files with the data to be imported into new tables (one table for each csv) and saves an sql file with the sql create tables commands<br>\n",
    "__Usage__\n",
    "1. Assign value to parameters \n",
    "1. Execute the tables_columns_2_rename function and save the results to file (one for tables and one for columns 2.\n",
    "1. Open the tables file: in the first column is the name of the file without textension and a comma. Fill in after the comma the name of the table; the file name will be added as a comment to the table.\n",
    "1. Open the columns file; similar process to the one performed with the table file.\n",
    "1. Execute the function write_sql_commands\n",
    "1. Open the file and, if desired, adjust the column types, comments, etc.\n",
    "1. Execute the file with psql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460d44af-f719-45cc-a6bb-80e95c30c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from os.path import join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5684c-d4cf-49be-b662-043c841174a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad85e8ae-5497-43ac-be84-33a69238e5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tables_columns_2_rename(files: [str], to_screen: bool=False) -> [[str], [str]]:\n",
    "    \"\"\"\n",
    "    Escribe el nombre de todas las tablas en files para ser renombradas como nombre de las tablas\n",
    "    Extrae la cabecera de cada fichero csv y escribe en un fichero todas la cabeceras para que sean\n",
    "    renombradas como las columnas de las tablas\n",
    "    ----\n",
    "    files: lista de paths csv a tratar\n",
    "    to_screen: if True print intermediate results\n",
    "    ---\n",
    "    return [name_tables, name_columns]\n",
    "    name_tables: nombres de los ficheros sin path\n",
    "    name_columns: nombres de las columnas\n",
    "    \"\"\"\n",
    "    name_tables = []\n",
    "    name_columns = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode='r', encoding='utf-8') as fi:\n",
    "            rfi = csv.reader(fi, delimiter=',')\n",
    "            table_name, _ = os.path.basename(file).split('.')\n",
    "            name_tables.append(table_name)\n",
    "            for ir, row in enumerate(rfi):\n",
    "                if to_screen:\n",
    "                    print(table_name)\n",
    "                    print(row)\n",
    "                    print('')\n",
    "                for col1 in row:\n",
    "                    if col1 not in name_columns:\n",
    "                        name_columns.append(col1)\n",
    "                break\n",
    "\n",
    "    return name_tables, name_columns\n",
    "\n",
    "\n",
    "def names_get(file: str) -> {str:str}:\n",
    "    \"\"\"\n",
    "    file: path/file con los nombres (tablas o columnas según file) en los ficheros\n",
    "        csv y los que se van a utilizar en las tablas\n",
    "    ----\n",
    "    return:\n",
    "    dict en el que key es el nombre en el fichero csv y atrib es nombre a utilizar\n",
    "    \"\"\"\n",
    "    with open(file, 'r', encoding='utf-8') as fi:\n",
    "        rfi = csv.reader(fi, delimiter=',')\n",
    "        names = [(row[0], row[1])  for row in rfi]\n",
    "    return dict(names)\n",
    "        \n",
    "\n",
    "def sets_get():\n",
    "    \"\"\"\n",
    "    valores de los parámetros para escribir en el fichero sql donde se crean las tablas\n",
    "    \"\"\"\n",
    "    sets = \\\n",
    "\"\"\"\n",
    "-- PostgreSQL database dump\n",
    "\n",
    "SET statement_timeout = 0;\n",
    "SET lock_timeout = 0;\n",
    "SET idle_in_transaction_session_timeout = 0;\n",
    "SET client_encoding = 'UTF8';\n",
    "SET standard_conforming_strings = on;\n",
    "SELECT pg_catalog.set_config('search_path', '', false);\n",
    "SET check_function_bodies = false;\n",
    "SET xmloption = content;\n",
    "SET client_min_messages = warning;\n",
    "SET row_security = off;\n",
    "\n",
    "SET default_tablespace = '';\n",
    "\n",
    "SET default_table_access_method = heap;\n",
    "\n",
    "\"\"\"    \n",
    "    return sets\n",
    "\n",
    "\n",
    "def write_sql_commands(dst: str, files: [str], table_names: {str:str}, column_names: {str:str},\n",
    "                             schema: [str]='tmp', comment_prefix: str='',  to_screen: bool=False):\n",
    "    \"\"\"\n",
    "    Escribe el fichero sql con los comandos create table \n",
    "    ----\n",
    "    dst: path/fichero de resultados\n",
    "    files: lista de paths csv a tratar\n",
    "    table_names: dict {name in csv : name in table}\n",
    "    column_names: dict {name in csv : name in table}\n",
    "    schema: donde se crearán las tablas\n",
    "    to_screen: if True print intermediate results\n",
    "    ---\n",
    "    return None\n",
    "    \"\"\"\n",
    "    with open(dst, 'w', encoding='utf-8') as fo:\n",
    "        fo.write(sets_get())\n",
    "        for file in files:\n",
    "            col_names = []\n",
    "            with open(file, mode='r', encoding='utf-8') as fi:\n",
    "                rfi = csv.reader(fi, delimiter=',')\n",
    "                file_name, _ = os.path.basename(file).split('.')\n",
    "                if file_name in table_names:\n",
    "                    tab_name = table_names[file_name]\n",
    "                else:\n",
    "                    raise ValueError(f'No se localiza {file_name}')\n",
    "\n",
    "                for ir, row in enumerate(rfi):\n",
    "                    if to_screen:\n",
    "                        print(table_name)\n",
    "                        print(row)\n",
    "                        print('')\n",
    "                    for col1 in row:\n",
    "                        if col1 in column_names:\n",
    "                            col_names.append(column_names[col1])\n",
    "                        else:\n",
    "                            raise ValueError(f'No se localiza {col1}')\n",
    "                            \n",
    "                    sql_command = sql_command_get(schema, tab_name, file_name, col_names, row, comment_prefix)\n",
    "                    \n",
    "                    if to_screen:\n",
    "                        print(table_names[file_name])\n",
    "                    break\n",
    "            \n",
    "            fo.write(f'{sql_command}\\n\\n')\n",
    "        \n",
    "        return\n",
    "\n",
    "    \n",
    "def sql_command_get(schema: str, table_name: str, table_comment: str, \n",
    "                    col_names: [str], col_comments: [str]) -> str :\n",
    "    \"\"\"\n",
    "    sets the sql commands for a table \n",
    "    \"\"\"\n",
    "    cols = [col1 + ' varchar' for col1 in col_names]\n",
    "    cols = ',\\n'.join(cols)\n",
    "    if len(schema) > 0:\n",
    "        schema = schema + '.'\n",
    "    table_comment = table_comment.replace('_', ' ')\n",
    "    comment = f\"comment on table {schema}{table_name} is '{comment_prefix} {table_comment}';\\n\"\n",
    "    \n",
    "    comment_columns = [f\"comment on columnn {schema}{table_name}.{coln} is '{colc}';\" for coln, colc in zip(col_names, col_comments)]\n",
    "    comment_columns = '\\n'.join(comment_columns)\n",
    "    \n",
    "    command = f\"\"\"\n",
    "create table if not exists {schema}{table_name} (\n",
    "{cols}    \n",
    ");\n",
    "\n",
    "{comment}\n",
    "{comment_columns}\n",
    "    \"\"\"\n",
    "    return command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a163f-f5c4-455b-9380-34bdb8252751",
   "metadata": {},
   "source": [
    "## Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be60561e-6a1b-4b49-ae02-4ca97ee9201d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directorio y máscara to get csv files\n",
    "drt = r'E:\\PPHH\\chj_22_27\\tablas'\n",
    "mask = '*.csv'\n",
    "\n",
    "# file_name_tables: nombre del fichero donde se grabarán el nombre d elas tablas\n",
    "file_name_tables = join(drt, '01_table_names.txt')\n",
    "# file_name_columns: nombre del fichero donde se grabarán el nombre de las columnas \n",
    "file_name_columns = join(drt, '02_colum_names.txt')\n",
    "\n",
    "# fo_name: nombre del fichero donde se grabarán los comandos parara creación de las tablas\n",
    "fo_name = join(drt, '03_create_tables.sql')\n",
    "\n",
    "# schema: nombre del esquema de la DB donde se crearán las tablas\n",
    "schema = 'tmp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf759f-aef5-4fb3-8a36-3e3990fcd215",
   "metadata": {},
   "source": [
    "## Function 1. Write names of files and columns\n",
    "After saving the 2 files (tables and columns), each file must be edited and the new names must be given manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d89b6e-181c-4771-9b4b-79ed19df2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(join(drt, mask))\n",
    "\n",
    "tables, columns = tables_columns_2_rename(files)\n",
    "\n",
    "with open(file_name_tables, 'w', encoding='utf-8') as fo:\n",
    "    fo.write('name,new_name\\n')\n",
    "    for t1 in tables:\n",
    "        fo.write(f'{t1},\\n')\n",
    "\n",
    "with open(file_name_columns, 'w', newline='', encoding='utf-8') as fo:\n",
    "    fo.write('name,new_name\\n')\n",
    "    for c1 in columns:\n",
    "        fo.write(f'{c1},\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d002fd0-41e6-4d3c-9881-37c5c15b0057",
   "metadata": {},
   "source": [
    "## Function 2. write_sql_commands\n",
    "After assigning the names of the tables and columns from the 2 files created in the previous cell, an sql file is created in which the tables are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e79cbd-1eae-4e02-a873-c99880bff7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = names_get(join(drt, '01_table_names_done.txt'))\n",
    "column_names = names_get(join(drt, '02_colum_names_done.txt'))\n",
    "\n",
    "write_sql_commands(fo_name, files, table_names, column_names, schema, comment_prefix='CHJ Plan Hidrológico 21-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6965e3-431f-4ac8-8e74-b801942428b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
