{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9b9583-a1fe-49c5-beca-16d8a3029144",
   "metadata": {},
   "source": [
    "# Create table from csv files (basic)\n",
    "Lee una serie de ficheros csv con los datos que se desean importar a nuevas tablas (una tabla para cada csv)<br>\n",
    "__Uso__\n",
    "1. Asignar valor a los parámetros \n",
    "1. Ejecutar la función tables_columns_2_rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460d44af-f719-45cc-a6bb-80e95c30c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import os\n",
    "from os.path import join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5684c-d4cf-49be-b662-043c841174a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad85e8ae-5497-43ac-be84-33a69238e5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tables_columns_2_rename(files: [str], to_screen: bool=False) -> [[str], [str]]:\n",
    "    \"\"\"\n",
    "    Escribe el nombre de todas las tablas en files para ser renombradas como nombre de las tablas\n",
    "    Extrae la cabecera de cada fichero csv y escribe en un fichero todas la cabeceras para que sean\n",
    "    renombradas como las columnas de las tablas\n",
    "    ----\n",
    "    files: lista de paths csv a tratar\n",
    "    to_screen: if True print intermediate results\n",
    "    ---\n",
    "    return [name_tables, name_columns]\n",
    "    name_tables: nombres de los ficheros sin path\n",
    "    name_columns: nombres de las columnas\n",
    "    \"\"\"\n",
    "    name_tables = []\n",
    "    name_columns = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode='r', encoding='utf-8') as fi:\n",
    "            rfi = csv.reader(fi, delimiter=',')\n",
    "            table_name, _ = os.path.basename(file).split('.')\n",
    "            name_tables.append(table_name)\n",
    "            for ir, row in enumerate(rfi):\n",
    "                if to_screen:\n",
    "                    print(table_name)\n",
    "                    print(row)\n",
    "                    print('')\n",
    "                for col1 in row:\n",
    "                    if col1 not in name_columns:\n",
    "                        name_columns.append(col1)\n",
    "                break\n",
    "\n",
    "    return name_tables, name_columns\n",
    "\n",
    "\n",
    "def names_get(file: str) -> dict:\n",
    "    \"\"\"\n",
    "    file: path/file con los nombres (tablas o columnas según file) en los ficheros\n",
    "        csv y los que se van a utilizar en las tablas\n",
    "    ----\n",
    "    return:\n",
    "    dict en el que key es el nombre en el fichero csv y atrib es nombre a utilizar\n",
    "    \"\"\"\n",
    "    with open(file, 'r', encoding='utf-8') as fi:\n",
    "        rfi = csv.reader(fi, delimiter=',')\n",
    "        names = [(row[0], row[1])  for row in rfi]\n",
    "    return dict(names)\n",
    "        \n",
    "\n",
    "def sets_get():\n",
    "    \"\"\"\n",
    "    valores de los parámetros para escribir en el fichero sql donde se crean las tablas\n",
    "    \"\"\"\n",
    "    sets = \\\n",
    "\"\"\"\n",
    "-- PostgreSQL database dump\n",
    "\n",
    "SET statement_timeout = 0;\n",
    "SET lock_timeout = 0;\n",
    "SET idle_in_transaction_session_timeout = 0;\n",
    "SET client_encoding = 'UTF8';\n",
    "SET standard_conforming_strings = on;\n",
    "SELECT pg_catalog.set_config('search_path', '', false);\n",
    "SET check_function_bodies = false;\n",
    "SET xmloption = content;\n",
    "SET client_min_messages = warning;\n",
    "SET row_security = off;\n",
    "\n",
    "SET default_tablespace = '';\n",
    "\n",
    "SET default_table_access_method = heap;\n",
    "\n",
    "\"\"\"    \n",
    "    return sets\n",
    "\n",
    "\n",
    "def tables_columns_translate(files: [str], to_screen: bool=False) -> [[str], [str]]:\n",
    "    \"\"\"\n",
    "    \n",
    "    ----\n",
    "    files: lista de paths csv a tratar\n",
    "    to_screen: if True print intermediate results\n",
    "    ---\n",
    "    return [name_tables, name_columns]\n",
    "    name_tables: nombres de los ficheros sin path\n",
    "    name_columns: nombres de las columnas\n",
    "    \"\"\"\n",
    "    name_tables = []\n",
    "    name_columns = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode='r', encoding='utf-8') as fi:\n",
    "            rfi = csv.reader(fi, delimiter=',')\n",
    "            table_name, _ = os.path.basename(file).split('.')\n",
    "            name_tables.append(table_name)\n",
    "            for ir, row in enumerate(rfi):\n",
    "                if to_screen:\n",
    "                    print(table_name)\n",
    "                    print(row)\n",
    "                    print('')\n",
    "                for col1 in row:\n",
    "                    if col1 not in name_columns:\n",
    "                        name_columns.append(col1)\n",
    "                break\n",
    "\n",
    "    return name_tables, name_columns\n",
    "\n",
    "def create_table_sql(table_name, col_names, schema = ''):\n",
    "    cols = [col1 + ' varchar' for col1 in col_names]\n",
    "    cols = ',\\n'.join(cols)\n",
    "    if len(schema) > 0:\n",
    "        schema = schema + '.'\n",
    "    comment = f\"comment on table {schema}{table_name} is 'CHJ Plan Hidrológico 21-27 {table_name}';\\n\"\n",
    "    comment = comment.replace('_', ' ')\n",
    "    \n",
    "    comment_columns = [f\"comment on columnn {schema}{table_name}.{col1} is '{col1}';\" for col1 in col_names]\n",
    "    comment_columns = '\\n'.join(comment_columns)\n",
    "    \n",
    "    command = f\"\"\"\n",
    "create table if not exists {schema}{table_name} (\n",
    "{cols}    \n",
    ");\n",
    "\n",
    "{comment}\n",
    "{comment_columns}\n",
    "    \"\"\"\n",
    "    return command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a163f-f5c4-455b-9380-34bdb8252751",
   "metadata": {},
   "source": [
    "## Set parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be60561e-6a1b-4b49-ae02-4ca97ee9201d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directorio y expression to get csv files\n",
    "drt = r'E:\\PPHH\\chj_22_27\\tablas'\n",
    "mask = '*.csv'\n",
    "\n",
    "# file_name_tables: nombre del fichero donde se grabarán el nombre d elas tablas\n",
    "file_name_tables = join(drt, '01_table_names.txt')\n",
    "# file_name_columns: nombre del fichero donde se grabarán el nombre de las columnas \n",
    "file_name_columns = join(drt, '02_colum_names.txt')\n",
    "\n",
    "# fo_name: nombre del fichero donde se grabarán los comandos parara creación de las tablas\n",
    "fo_name = join(drt, '03_create_tables.sql')\n",
    "\n",
    "# schema: nombre del esquema de la DB donde se crearán las tablas\n",
    "schema = 'tmp'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cf759f-aef5-4fb3-8a36-3e3990fcd215",
   "metadata": {},
   "source": [
    "## Function 1. Write names of files and columns\n",
    "Después de crearse el fichero deben darse los nuevos nobres manualmente en el fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d89b6e-181c-4771-9b4b-79ed19df2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(join(drt, mask))\n",
    "\n",
    "tables, columns = tables_columns_2_rename(files)\n",
    "\n",
    "with open(file_name_tables, 'w', encoding='utf-8') as fo:\n",
    "    fo.write('name,new_name\\n')\n",
    "    for t1 in tables:\n",
    "        fo.write(f'{t1},\\n')\n",
    "\n",
    "with open(file_name_columns, 'w', newline='', encoding='utf-8') as fo:\n",
    "    fo.write('name,new_name\\n')\n",
    "    for c1 in columns:\n",
    "        fo.write(f'{c1},\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d002fd0-41e6-4d3c-9881-37c5c15b0057",
   "metadata": {},
   "source": [
    "## Function 2. Write file create_tables.sql\n",
    "Después de asignar los nombres de las tablas y las columnas a partir de los 2 ficheros creados en la celda anterior, se crea un fichero sql en el que se crean las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e79cbd-1eae-4e02-a873-c99880bff7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = names_get(join(drt, '01_table_names_done.txt'))\n",
    "column_names = names_get(join(drt, '02_colum_names_done.txt'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e6965e3-431f-4ac8-8e74-b801942428b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'new_name',\n",
       " 'Código Masa subterránea': 'msbt_id',\n",
       " 'Masa subterránea': 'msbt_name',\n",
       " 'Recurso renovable': 'recurso_renov',\n",
       " 'Restricciones ambientales': 'retrict_amb',\n",
       " 'Recurso disponible': 'recurso_disp',\n",
       " 'Bombeo total': 'bombeo_tot',\n",
       " 'Derecho total': 'derecho_tot',\n",
       " 'Derecho sección B': 'derecho_sec_b',\n",
       " 'Índice de explotación con usos K': 'ie_con_usos_k',\n",
       " 'Índice de explotación con derechos': 'ie_con_derechos',\n",
       " 'Código Masa': 'msbt_id',\n",
       " 'Nombre Masa': 'msbt_name',\n",
       " 'Facies hidroquímica': 'facies_hq',\n",
       " 'Motivo Mal Estado*': 'causa_mal_estado',\n",
       " 'Código masa superficial asociada en estado peor que bueno': 'msf_id_mal_estado',\n",
       " 'Nombre masa superficial asociada en estado peor que bueno': 'msf_name_mal_estado',\n",
       " 'Cumple caudal ecológico mínimo': 'cumple_q_ecolog_min',\n",
       " 'Índice de explotación': 'ie',\n",
       " 'Evaluación tendencia piezométrica': 'tendencia_pz',\n",
       " 'Estado test 2 masas superficiales asociadas': 'estado_t2_msf',\n",
       " 'EDA dañado o en riesgo': 'eda_damaged_risk',\n",
       " 'Descenso piezométrico redes': 'pz_descenso_red',\n",
       " 'Estado test 3 EDAS': 'estado_t3_edas',\n",
       " 'Incumplimiento cloruros': 'cl_incumple',\n",
       " 'Incumplimiento de sulfatos': 'so4_incumple',\n",
       " 'Tendencia ascendente cloruros': 'cl_tendencia_alza',\n",
       " 'Tendencia ascendente sulfatos': 'so4_tendencia_alza',\n",
       " 'Incumplimientos superiores al doble del VU cloruros': 'incumpl_gt_2vucl',\n",
       " 'Incumplimientos superiores al doble del VU sulfatos': 'incumpl_gt_2vuso4',\n",
       " 'Estado test 4 intrusión marina': 'estado_t4_intrusio',\n",
       " 'Estado test 1 balance hídrico': 'estado_t1_balance_hidr',\n",
       " 'Estado cuantitativo global': 'estado_cuanti_global',\n",
       " 'Código Masa subt.': 'msbt_id',\n",
       " 'Parámetro de incumplimiento': 'param_incumple',\n",
       " 'Estado test 1 general estado químico': 'estado_t1_general_q',\n",
       " 'Supera norma calidad nitratos': 'gt_norma_no3',\n",
       " 'Supera valor umbral otros parámetros': 'gt_umbral_otros_param',\n",
       " 'Estado test 3 masas superficiales asociadas': 'estado_t3_msf',\n",
       " 'Estado test 4 EDAS': 'estado_t4_edas',\n",
       " 'Parámetro que incumple la norma de calidad': 'param_incumple_norma',\n",
       " 'Parámetro que incumple el valor umbral establecido': 'param_gt_umbral',\n",
       " 'Estado test 5 zonas protegidas': 'estado_t5_zonas_proteg',\n",
       " 'Test 1 evaluación general calidad': 't1_general_cali',\n",
       " 'Test 2 salinización': 't2_salinidad',\n",
       " 'Test 3 masas superficiales asociadas': 't3_msf',\n",
       " 'Test 4 EDAS': 't4_edas',\n",
       " 'Test 5 zonas protegidas': 't5_z_protegid',\n",
       " 'Estado químico representativo': 'estado_quim_repr',\n",
       " 'Est. Cuantitativo': 'estado_cuanti',\n",
       " 'Est. Químico': 'estado_quim',\n",
       " 'Estado Global': 'estado_global',\n",
       " 'Código masa': 'msbt_id',\n",
       " 'Sup. Total (km2)': 'sup_km2',\n",
       " '% Carbonatada': 'porc_carb',\n",
       " '% Detrítica': 'porc_detr',\n",
       " '% Evaporita': 'porc_evap',\n",
       " '% otros/sin información': 'porc_otros'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826fae9-d9ff-45ca-9b33-a90642b4ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fo_name, 'w') as fo:\n",
    "    fo.write(sets_get())\n",
    "    for file in files:\n",
    "        with open(file, mode='r', encoding='utf-8') as fi:\n",
    "            rfi = csv.reader(fi, delimiter=',')\n",
    "            table_name, _ = os.path.basename(file).split('.')\n",
    "            for ir, row in enumerate(rfi):\n",
    "                print(table_name)\n",
    "                print(row)\n",
    "                print('')\n",
    "                sql_command = create_table_sql(table_name, row, schema = schema)\n",
    "                break\n",
    "            fo.write(f'{sql_command}\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
